{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bd515c",
   "metadata": {},
   "source": [
    "## ml projec pipeline\n",
    "1. import required lib\n",
    "2. load the dataset\n",
    "3. data preprocessing\n",
    "4. EDA\n",
    "5. Features Engineering\n",
    "6. Train and Splitting\n",
    "7. Train Model\n",
    "8. Predict Model\n",
    "9. Model Evaluation Metrics\n",
    "10. Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f01c7c",
   "metadata": {},
   "source": [
    "# ðŸŒ² Random Forest (Machine Learning)\n",
    "\n",
    "## What is Random Forest?\n",
    "**Random Forest** is an **ensemble learning algorithm** that builds **multiple Decision Trees** and combines their predictions to produce a more **accurate and stable** result.\n",
    "\n",
    "Instead of relying on one decision tree, Random Forest uses the **collective decision of many trees**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Random Forest?\n",
    "Decision Trees often suffer from:\n",
    "- Overfitting\n",
    "- High variance\n",
    "\n",
    "Random Forest reduces these problems by:\n",
    "- Training trees on **different samples of data**\n",
    "- Using **random subsets of features**\n",
    "- Combining predictions through voting or averaging\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea\n",
    "> **Many decision trees + randomness = better performance**\n",
    "\n",
    "---\n",
    "\n",
    "## How Random Forest Works\n",
    "\n",
    "### 1. Bootstrapping (Row Sampling)\n",
    "- Random samples are drawn from the original dataset **with replacement**\n",
    "- Each decision tree is trained on a **different dataset**\n",
    "\n",
    "This technique is called **Bagging (Bootstrap Aggregating)**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Feature Randomness (Column Sampling)\n",
    "- At each split, only a **random subset of features** is considered\n",
    "- This ensures trees are **less correlated**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Train Multiple Decision Trees\n",
    "- Each tree is trained independently\n",
    "- Trees are usually grown deep to reduce bias\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Combine Predictions\n",
    "- **Classification** â†’ Majority voting\n",
    "- **Regression** â†’ Average of predictions\n",
    "\n",
    "---\n",
    "\n",
    "## Prediction Method\n",
    "\n",
    "### Classification\n",
    "If tree predictions are:\n",
    "- Tree 1 â†’ Yes  \n",
    "- Tree 2 â†’ No  \n",
    "- Tree 3 â†’ Yes  \n",
    "\n",
    "Final output = **Yes**\n",
    "\n",
    "---\n",
    "\n",
    "### Regression\n",
    "If tree predictions are:\n",
    "- 40, 45, 50  \n",
    "\n",
    "Final output = **(40 + 45 + 50) / 3 = 45**\n",
    "\n",
    "---\n",
    "\n",
    "## Important Hyperparameters\n",
    "| Parameter | Description |\n",
    "|--------|------------|\n",
    "| `n_estimators` | Number of trees |\n",
    "| `max_depth` | Maximum depth of trees |\n",
    "| `max_features` | Features considered at each split |\n",
    "| `min_samples_split` | Minimum samples to split |\n",
    "| `bootstrap` | Enables bootstrapping |\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of Random Forest\n",
    "- Reduces overfitting\n",
    "- High accuracy\n",
    "- Handles large datasets well\n",
    "- Works with non-linear data\n",
    "- Provides feature importance\n",
    "\n",
    "---\n",
    "\n",
    "## Disadvantages of Random Forest\n",
    "- Less interpretable than a single decision tree\n",
    "- Slower training time\n",
    "- Requires more memory\n",
    "\n",
    "---\n",
    "\n",
    "## Random Forest vs Decision Tree\n",
    "\n",
    "| Feature | Decision Tree | Random Forest |\n",
    "|------|---------------|---------------|\n",
    "| Overfitting | High | Low |\n",
    "| Accuracy | Medium | High |\n",
    "| Stability | Low | High |\n",
    "| Interpretability | High | Medium |\n",
    "| Training Time | Fast | Slower |\n",
    "\n",
    "---\n",
    "\n",
    "## Applications of Random Forest\n",
    "- Fraud detection\n",
    "- Credit scoring\n",
    "- Medical diagnosis\n",
    "- Customer churn prediction\n",
    "- Recommendation systems\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "Random Forest is a powerful algorithm that improves Decision Trees by using **ensemble learning and randomness**.  \n",
    "It provides better accuracy, stability, and generalization compared to a single decision tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0070eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9177fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('RF datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2caa22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age    salary  experience_years education_level department city_tier  \\\n",
      "0   56  136748.0                33             PhD         IT    Tier-3   \n",
      "1   46   25287.0                28     High School    Finance    Tier-2   \n",
      "2   32  146593.0                 3             PhD         HR    Tier-1   \n",
      "3   60   54387.0                16     High School         IT    Tier-3   \n",
      "4   25   28512.0                34        Bachelor    Finance    Tier-2   \n",
      "\n",
      "   work_hours_per_week  performance_score  promotion_last_5years  \\\n",
      "0                   47           3.800000                      0   \n",
      "1                   40           2.400000                      1   \n",
      "2                   45           2.970316                      0   \n",
      "3                   47           2.600000                      0   \n",
      "4                   64           1.900000                      0   \n",
      "\n",
      "   target_left_company  \n",
      "0                    1  \n",
      "1                    1  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087c9f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   age                    1000 non-null   int64  \n",
      " 1   salary                 1000 non-null   float64\n",
      " 2   experience_years       1000 non-null   int64  \n",
      " 3   education_level        1000 non-null   object \n",
      " 4   department             1000 non-null   object \n",
      " 5   city_tier              1000 non-null   object \n",
      " 6   work_hours_per_week    1000 non-null   int64  \n",
      " 7   performance_score      1000 non-null   float64\n",
      " 8   promotion_last_5years  1000 non-null   int64  \n",
      " 9   target_left_company    1000 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 78.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47cd9c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age         salary  experience_years  work_hours_per_week  \\\n",
      "count  1000.000000    1000.000000        1000.00000          1000.000000   \n",
      "mean     40.986000   85084.980000          19.34500            49.554000   \n",
      "std      13.497852   37146.053131          11.45492            11.255833   \n",
      "min      18.000000   20060.000000           0.00000            30.000000   \n",
      "25%      29.000000   53704.250000          10.00000            40.000000   \n",
      "50%      42.000000   84772.000000          19.00000            49.000000   \n",
      "75%      52.000000  116535.500000          29.00000            59.000000   \n",
      "max      64.000000  149972.000000          39.00000            69.000000   \n",
      "\n",
      "       performance_score  promotion_last_5years  target_left_company  \n",
      "count        1000.000000            1000.000000          1000.000000  \n",
      "mean            2.970316               0.511000             0.497000  \n",
      "std             1.128795               0.500129             0.500241  \n",
      "min             1.000000               0.000000             0.000000  \n",
      "25%             2.000000               0.000000             0.000000  \n",
      "50%             2.970316               1.000000             0.000000  \n",
      "75%             3.900000               1.000000             1.000000  \n",
      "max             5.000000               1.000000             1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3548f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      0\n",
       "salary                   0\n",
       "experience_years         0\n",
       "education_level          0\n",
       "department               0\n",
       "city_tier                0\n",
       "work_hours_per_week      0\n",
       "performance_score        0\n",
       "promotion_last_5years    0\n",
       "target_left_company      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b24d4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department\n",
       "IT            225\n",
       "Finance       201\n",
       "Operations    199\n",
       "HR            190\n",
       "Marketing     185\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15d35af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "High School    299\n",
       "PhD            244\n",
       "Master         232\n",
       "Bachelor       225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54300828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_tier\n",
       "Tier-3    349\n",
       "Tier-2    336\n",
       "Tier-1    315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city_tier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e189dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "cate_cols = ['department','education_level','city_tier']\n",
    "oh_df = pd.DataFrame(ohe.fit_transform(df[cate_cols]), columns=ohe.get_feature_names_out(cate_cols))\n",
    "df = pd.concat([df.drop(columns=cate_cols), oh_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e45ec74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age    salary  experience_years  work_hours_per_week  performance_score  \\\n",
      "0   56  136748.0                33                   47           3.800000   \n",
      "1   46   25287.0                28                   40           2.400000   \n",
      "2   32  146593.0                 3                   45           2.970316   \n",
      "3   60   54387.0                16                   47           2.600000   \n",
      "4   25   28512.0                34                   64           1.900000   \n",
      "\n",
      "   promotion_last_5years  target_left_company  department_HR  department_IT  \\\n",
      "0                      0                    1            0.0            1.0   \n",
      "1                      1                    1            0.0            0.0   \n",
      "2                      0                    0            1.0            0.0   \n",
      "3                      0                    0            0.0            1.0   \n",
      "4                      0                    1            0.0            0.0   \n",
      "\n",
      "   department_Marketing  department_Operations  education_level_High School  \\\n",
      "0                   0.0                    0.0                          0.0   \n",
      "1                   0.0                    0.0                          1.0   \n",
      "2                   0.0                    0.0                          0.0   \n",
      "3                   0.0                    0.0                          1.0   \n",
      "4                   0.0                    0.0                          0.0   \n",
      "\n",
      "   education_level_Master  education_level_PhD  city_tier_Tier-2  \\\n",
      "0                     0.0                  1.0               0.0   \n",
      "1                     0.0                  0.0               1.0   \n",
      "2                     0.0                  1.0               0.0   \n",
      "3                     0.0                  0.0               0.0   \n",
      "4                     0.0                  0.0               1.0   \n",
      "\n",
      "   city_tier_Tier-3  \n",
      "0               1.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               1.0  \n",
      "4               0.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=df.drop(columns=['target_left_company'])\n",
    "y=df['target_left_company']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=9137)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb69359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.495\n",
      "Confusion Matrix:\n",
      " [[49 50]\n",
      " [51 50]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49        99\n",
      "           1       0.50      0.50      0.50       101\n",
      "\n",
      "    accuracy                           0.49       200\n",
      "   macro avg       0.49      0.49      0.49       200\n",
      "weighted avg       0.50      0.49      0.50       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100,random_state=9137)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred=rf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac601be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actaul  Predicted\n",
      "269       1          1\n",
      "686       1          0\n",
      "473       0          0\n",
      "811       1          1\n",
      "344       1          0\n",
      "24        1          0\n",
      "982       1          1\n",
      "336       0          1\n",
      "584       0          1\n",
      "619       0          0\n"
     ]
    }
   ],
   "source": [
    "comp_df=pd.DataFrame({'Actaul':y_test,'Predicted':y_pred})\n",
    "print(comp_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e0b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
